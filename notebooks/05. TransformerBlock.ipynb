{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f964f10f",
   "metadata": {},
   "source": [
    "# Playground for TransformerBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb2765",
   "metadata": {},
   "source": [
    "## Central Component of GPT Model\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "225ec960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------- initializing Multi Head Attention ----------------\n",
      "\n",
      "\n",
      "=== MultiHeadAttention Initialization ===\n",
      "    input_dim = 768\n",
      "    output_dim = 128\n",
      "    num_heads = 8\n",
      "    head_dim = 16\n",
      "    Generating nn.Linear(768, 128) weights for query, key and value\n",
      "    Generating causal diagonal mask torch.triu(torch.ones(4, 4), diagonal=1) for causal masking of attn_scores\n",
      "    Generating dropout nn.Dropout(0.2) for random dropout of attn_weights\n",
      "    Generating optional nn.Linear(128, 128) weights for final context_vector projection\n",
      "=== End MultiHeadAttention Initialization ===\n",
      "\n",
      "\n",
      "\n",
      "----- Using real data input (see DataPreparation.ipynb) --\n",
      "\n",
      "\n",
      "=== Embedder Initialization ===\n",
      "    vocab_size =  50252\n",
      "    context_length =  4\n",
      "    embedding_dim =  768\n",
      "    Generating token_embeddings (50252 x 768)\n",
      "    Generating pos_embeddings (4 x 768)\n",
      "=== End Initialization ===\n",
      "\n",
      "Displaying first row of batch\n",
      "\n",
      "First batch elements Input x:\n",
      " tensor([15424,   373,   257,  5909])  archive was a vast\n",
      "\n",
      "First batch elements Target y:\n",
      " tensor([  373,   257,  5909, 16099])  was a vast repository\n",
      "\n",
      "=== Embedder Forward Pass ===\n",
      "\n",
      "embeddings[0] for x (4 x 768):\n",
      " tensor([[-0.9710, -0.7524, -0.8731,  ...,  0.7471, -0.9052, -0.2762],\n",
      "        [-1.9231, -0.6952, -1.9170,  ..., -1.5696, -0.5434,  0.5664],\n",
      "        [-0.4960, -1.1091, -0.4747,  ...,  0.8321,  0.0589,  1.5222],\n",
      "        [-0.7470, -0.4200, -0.0747,  ...,  1.1139,  0.2141, -0.1558]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "pos_embeddings[0] (4 x 768):\n",
      " tensor([[ 0.6610, -1.4272,  2.4605,  ...,  1.2418, -1.1110,  1.0747],\n",
      "        [-1.3963, -0.0800,  1.0716,  ..., -0.6346,  0.0893,  0.6827],\n",
      "        [-0.2487, -0.6259, -0.8370,  ...,  0.5769, -0.0376,  0.4348],\n",
      "        [ 0.9228,  0.5802, -0.2968,  ...,  1.3034, -0.4382,  0.5517]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "input_embeddings[0] = embeddings[0] + pos_embeddings[0]:\n",
      " tensor([[-0.3100, -2.1796,  1.5873,  ...,  1.9889, -2.0162,  0.7986],\n",
      "        [-3.3194, -0.7751, -0.8453,  ..., -2.2042, -0.4541,  1.2492],\n",
      "        [-0.7448, -1.7351, -1.3117,  ...,  1.4090,  0.0213,  1.9570],\n",
      "        [ 0.1758,  0.1602, -0.3716,  ...,  2.4173, -0.2241,  0.3959]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Shape for input_embeddings: batch, context, embedding_dim  torch.Size([8, 4, 768])\n",
      "=== End Forward Pass ===\n",
      "\n",
      "\n",
      "\n",
      "------- performing multi head attention ------------------\n",
      "\n",
      "\n",
      "=== MultiHeadAttention Forward Pass ===\n",
      "Input shape: torch.Size([8, 4, 768]) (batch_size=8, context_length=4, input_dim=768)\n",
      "Config: num_heads=8, head_dim=16, output_dim=128\n",
      "\n",
      "Input tensor (batch 0 with shape torch.Size([4, 768])):\n",
      " tensor([[-0.3100, -2.1796,  1.5873,  ...,  1.9889, -2.0162,  0.7986],\n",
      "        [-3.3194, -0.7751, -0.8453,  ..., -2.2042, -0.4541,  1.2492],\n",
      "        [-0.7448, -1.7351, -1.3117,  ...,  1.4090,  0.0213,  1.9570],\n",
      "        [ 0.1758,  0.1602, -0.3716,  ...,  2.4173, -0.2241,  0.3959]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "1. QKV Projection:\n",
      "   QKV shapes: torch.Size([8, 4, 128])\n",
      "\n",
      "2. Split into heads:\n",
      "(batch_size, context_length, output_dim) -> (batch_size, context_length, head_num, head_dim)\n",
      "   QKV shapes after view: torch.Size([8, 4, 8, 16])\n",
      "\n",
      "3. Transpose for attention computation:\n",
      "(batch_size, context_length, num_heads, head_dim) -> (batch_size, num_head, context_length, head_dim)\n",
      "   QKV shapes after transpose: torch.Size([8, 8, 4, 16])\n",
      "\n",
      "4. Attention scores computation:\n",
      "   attn_scores shape: torch.Size([8, 8, 4, 4])\n",
      "   Scale factor (1/sqrt(head_dim)): 0.2500\n",
      "   Raw attention scores for head 0, batch 0:\n",
      "tensor([[     0.9869,      0.1571,      0.5277,      0.3707],\n",
      "        [    -2.9761,      0.2798,     -0.2150,      3.0631],\n",
      "        [     1.2814,      1.2523,      2.7011,     -0.0008],\n",
      "        [    -0.3890,      0.9923,      0.2040,      3.0814]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "5. Causal masking:\n",
      "   Causal mask:\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "   Then masked_fill True -> -torch.inf\n",
      "\n",
      "   Masked attention scores for head 0, batch 0:\n",
      "tensor([[ 0.9869,    -inf,    -inf,    -inf],\n",
      "        [-2.9761,  0.2798,    -inf,    -inf],\n",
      "        [ 1.2814,  1.2523,  2.7011,    -inf],\n",
      "        [-0.3890,  0.9923,  0.2040,  3.0814]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "6. Softmax attention weights:\n",
      "   attn_weights shape: torch.Size([8, 8, 4, 4])\n",
      "   Attention weights for head 0, batch 0:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3070, 0.6930, 0.0000, 0.0000],\n",
      "        [0.2925, 0.2904, 0.4171, 0.0000],\n",
      "        [0.1680, 0.2372, 0.1948, 0.4000]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "   Sum of weights (should be ~1.0): tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "\n",
      "7. After dropout:\n",
      "   Attention weights after dropout for head 0, batch 0:\n",
      "tensor([[1.2500, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3838, 0.8662, 0.0000, 0.0000],\n",
      "        [0.3656, 0.3630, 0.5214, 0.0000],\n",
      "        [0.2100, 0.2966, 0.2435, 0.5000]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "8. Compute context vectors:\n",
      "   context_vec shape after attention: torch.Size([8, 4, 8, 16])\n",
      "   First context vector (batch 0, token 0, head 0): tensor([ 1.2020,  0.8138,  0.1125,  0.1420, -0.0517,  0.3173, -1.8397, -0.9432,\n",
      "        -0.1389,  1.6354,  0.6562, -0.8412,  1.0339, -0.9603,  1.5243,  0.2921],\n",
      "       grad_fn=<SelectBackward0>)...\n",
      "\n",
      "9. Concatenate heads:\n",
      "   context_vec shape after view: torch.Size([8, 4, 128])\n",
      "   First concatenated context vector (batch 0): tensor([[     1.2020,      0.8138,      0.1125,      0.1420,     -0.0517,\n",
      "              0.3173,     -1.8397,     -0.9432,     -0.1389,      1.6354,\n",
      "              0.6562,     -0.8412,      1.0339,     -0.9603,      1.5243,\n",
      "              0.2921,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      1.7353,\n",
      "              0.4753,     -2.1176,      0.4204,     -0.5770,      1.1375,\n",
      "             -0.5424,     -0.8481,     -0.0430,     -0.3872,     -0.7311,\n",
      "             -1.5362,     -0.2595,      1.5613,      0.3065,      0.4686,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.1892,     -2.0398,     -0.7310,     -1.1861,\n",
      "             -1.3698,     -0.3969,      2.1243,     -0.1451,      0.4116,\n",
      "             -0.3931,     -0.4757,     -0.0471,      0.0297,      0.7218,\n",
      "             -1.9437,     -1.1326,      0.1148,     -0.3320,      0.3840,\n",
      "              0.0737,     -0.0150,     -0.2663,     -1.6948,     -0.3815,\n",
      "              0.5604,      1.5224,      1.0008,      0.2064,      0.1108,\n",
      "             -0.0609,     -1.3077,     -1.6534],\n",
      "        [    -0.3941,      1.1060,      0.4858,     -0.4584,      0.8045,\n",
      "              2.3833,     -0.0915,     -0.5381,      0.4133,      0.6249,\n",
      "              1.5415,      1.2137,      0.4607,      0.5880,     -0.9849,\n",
      "              0.2987,      0.7561,      0.1269,     -0.4880,     -0.5548,\n",
      "              1.2614,      0.0938,     -0.0198,     -1.0280,      0.5008,\n",
      "             -0.4226,     -1.3240,     -1.0724,      1.0958,      0.7529,\n",
      "             -0.9574,      0.5333,     -1.0827,      0.5285,      0.0590,\n",
      "              1.8240,     -0.8297,     -1.6491,      0.2089,     -0.8144,\n",
      "             -0.3314,      0.6166,     -0.3374,     -1.3343,     -0.1290,\n",
      "             -0.2044,     -0.0027,      0.3385,     -0.4626,     -0.3491,\n",
      "             -0.2982,      0.2333,     -0.6871,      0.2784,      0.0388,\n",
      "             -0.5394,      0.0124,      0.1294,      0.8300,      0.8132,\n",
      "              0.6342,      1.0871,      0.5968,     -1.4612,      0.8360,\n",
      "              0.0022,     -1.6951,     -0.1462,     -1.1896,      0.9879,\n",
      "             -0.6928,     -0.5189,      0.1719,     -0.2051,     -1.3303,\n",
      "             -1.0255,      0.0485,      0.1958,     -0.3033,      0.1059,\n",
      "              0.4177,     -0.4924,      0.1193,      0.9894,     -0.7531,\n",
      "             -1.4132,     -0.3069,     -1.1256,      0.4150,     -0.1003,\n",
      "              0.9071,     -0.6535,      0.0873,      0.0270,     -0.7873,\n",
      "              0.2105,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,     -0.0537,     -0.0268,      0.2131,\n",
      "             -0.5433,      0.0868,     -2.3269,     -1.3004,      0.5336,\n",
      "              0.5270,      1.5433,      0.3365,      0.5299,     -0.4550,\n",
      "              0.2934,     -0.8986,     -0.7772],\n",
      "        [    -0.6159,     -1.8941,      0.1979,     -0.1304,      0.5263,\n",
      "              0.1342,     -0.5054,     -1.1389,     -0.0012,      0.3675,\n",
      "              0.7752,      1.0840,      0.4786,      0.0604,     -1.0169,\n",
      "             -0.2988,      0.4975,      0.1462,      0.6193,      0.4730,\n",
      "             -0.2482,     -0.0884,     -0.0611,     -0.8786,      0.7506,\n",
      "             -0.8786,     -0.4896,     -0.6163,      0.0344,      0.2306,\n",
      "              0.4207,     -0.5726,      0.2148,      0.0294,      0.5513,\n",
      "              0.5784,      0.3304,      0.3360,      0.4919,     -0.3446,\n",
      "              0.0530,     -0.2335,      0.0795,     -0.6881,      0.2717,\n",
      "             -0.2031,     -0.2599,      1.2340,      0.1300,      0.0618,\n",
      "             -0.8491,     -0.3385,      0.2061,      0.6130,     -0.1877,\n",
      "             -0.4772,      0.2098,      1.3401,      0.2189,      0.1668,\n",
      "             -0.0418,      0.4727,     -0.0285,     -0.4563,      0.1321,\n",
      "             -0.3931,     -0.6276,     -0.5780,     -1.1880,      0.6368,\n",
      "             -0.8010,     -0.1516,      0.5837,     -0.1684,     -1.3991,\n",
      "             -0.3583,      0.2516,     -0.3652,     -0.4164,     -0.0016,\n",
      "             -0.1088,      0.1499,     -0.4531,      0.3394,      0.1040,\n",
      "             -0.8903,      0.3840,     -0.7340,      0.1760,     -0.2985,\n",
      "              0.2899,     -0.2395,     -0.5445,      0.0287,      0.3464,\n",
      "             -0.2126,      0.2958,     -0.7008,      0.2195,     -0.3964,\n",
      "             -0.0861,      0.0745,      0.5559,      0.1354,     -0.0065,\n",
      "             -0.3531,      0.1543,     -0.1237,     -0.1769,      0.3371,\n",
      "             -0.1658,     -0.5096,     -0.4550,     -0.0930,     -0.8722,\n",
      "             -0.7691,     -0.6229,     -0.4840,      0.0529,      0.1269,\n",
      "             -0.4690,     -0.0059,      0.1851,     -0.1008,     -0.2821,\n",
      "              0.2168,     -0.0766,      0.2486],\n",
      "        [    -0.6037,     -0.4113,      0.4874,      0.0342,      0.3012,\n",
      "              0.3303,     -0.1876,     -0.9303,      0.8968,      0.7473,\n",
      "              0.7613,      1.7416,      0.5263,      0.5445,     -0.3326,\n",
      "              0.7903,      0.2978,     -0.4895,      0.2611,     -1.2240,\n",
      "              1.1705,      0.2645,     -0.1378,     -0.6126,      0.1643,\n",
      "              0.2316,      0.0529,     -0.0054,      0.4384,      0.7395,\n",
      "              0.5178,     -0.1887,      0.2745,      0.5724,      0.2287,\n",
      "             -0.1270,      0.0568,     -0.3104,     -1.6392,     -0.4775,\n",
      "             -1.1289,      0.1812,      0.6374,      0.4273,      0.5866,\n",
      "             -0.4527,      0.1693,      0.6780,     -0.6928,     -0.3778,\n",
      "             -0.0079,      0.7870,      0.8543,     -0.2715,      0.3101,\n",
      "             -0.4231,     -0.0597,     -0.0038,      0.1114,     -0.4943,\n",
      "             -0.0234,     -0.3215,      0.3238,     -0.5214,      0.4911,\n",
      "             -0.0702,     -0.5076,     -0.1524,     -0.4836,      0.4749,\n",
      "             -0.4937,     -0.2343,      0.3539,     -0.2161,     -0.6508,\n",
      "             -0.4341,      0.0338,      0.4316,      0.0375,      0.1883,\n",
      "              0.2246,     -0.1565,     -0.0087,      0.5326,     -0.3764,\n",
      "             -1.3376,      0.1125,     -0.6508,      0.0879,     -0.2337,\n",
      "              0.9019,     -0.3602,     -0.0441,     -0.0968,     -0.3133,\n",
      "              0.0142,      0.4911,     -0.8195,      0.5478,     -0.6462,\n",
      "              0.2697,     -0.3180,      0.3713,      0.0505,      0.1533,\n",
      "             -0.5520,      0.3759,     -0.3875,     -0.5558,      0.0848,\n",
      "             -0.3149,     -1.0740,     -0.4510,     -0.2450,     -0.8667,\n",
      "             -0.4944,     -0.6492,     -0.5969,     -0.2376,      0.1182,\n",
      "             -0.1238,     -0.0930,      0.1560,     -0.0267,     -0.6517,\n",
      "              0.5959,     -0.1206,      0.3433]], grad_fn=<SelectBackward0>)...\n",
      "\n",
      "10. Final output projection:\n",
      "   Final context_vec shape: torch.Size([8, 4, 128])\n",
      "   Final context vector (batch 0): tensor([[ 0.0067,  0.1619,  1.1435,  0.7072, -0.7486,  0.6573, -0.1626, -0.3244,\n",
      "          0.5068, -0.0166, -0.0610,  0.3889,  0.0783,  0.4400,  0.6432, -0.2443,\n",
      "         -0.6105, -0.6596,  0.1916, -0.1415, -0.5645, -0.1697, -0.0360, -0.0408,\n",
      "          0.1512, -0.1578,  0.4119, -0.0247,  0.4899,  0.5286, -0.3619,  0.1185,\n",
      "          0.3404,  0.0827, -0.1494,  0.1649, -0.1070,  0.1966, -0.5404, -0.2402,\n",
      "          0.6727,  0.1224,  0.2570, -0.0547,  0.1806,  0.0692,  0.6536, -0.7658,\n",
      "         -0.0797,  0.2564, -0.1324, -0.0870,  0.1398,  0.1496, -0.0818, -0.2543,\n",
      "         -0.3107,  0.1479, -0.3162,  0.4159, -0.2524, -0.2391, -0.1158, -0.2504,\n",
      "         -0.3283, -0.1371,  0.3052,  0.5194, -0.0813,  0.3079,  0.1968,  0.7248,\n",
      "          0.4668, -0.5753, -0.9502, -0.4340,  0.3416,  0.3270, -1.0362,  0.1704,\n",
      "          0.2531, -0.3697,  0.6193,  0.0968, -0.3090, -0.1135,  0.3695,  0.0045,\n",
      "          0.4712,  0.4979, -0.4673, -0.6364,  0.4005, -0.4416,  0.6769, -0.6666,\n",
      "          0.1951,  0.7035, -0.0850,  0.0967,  0.1873, -0.1527,  0.5867, -0.2968,\n",
      "          0.2900,  0.4079,  0.6444, -0.0494, -0.0521,  0.5826,  0.0697, -0.2265,\n",
      "          0.6078, -0.0838,  0.5353,  0.0986,  0.4727, -0.0426, -0.3527,  0.2215,\n",
      "         -0.6271, -0.5469, -0.1399, -0.4259, -0.4475, -0.0896, -0.0930, -0.5143],\n",
      "        [ 0.1657,  0.0323,  0.0308,  0.1475,  0.2242,  0.3576, -0.4391, -0.6660,\n",
      "          0.5691, -0.4164,  0.2887,  0.1199,  0.7616,  0.2446,  0.3085, -0.2553,\n",
      "         -0.1401,  0.0019,  0.0076, -0.1115, -0.4364, -0.1558, -0.1945, -0.3863,\n",
      "         -0.0935,  0.2954,  0.3182,  0.2683,  0.1544,  0.1925,  0.5108, -0.0438,\n",
      "         -0.3410,  0.1360, -0.6604, -0.2686, -0.0149, -0.1462,  0.6990,  0.1020,\n",
      "         -0.1618,  0.1751,  0.7201, -0.9712,  0.2023,  0.0185,  0.2046, -0.0838,\n",
      "          0.5741, -0.0179,  0.6619,  0.5334,  0.1758, -0.3412, -0.4444,  0.6632,\n",
      "          0.5340,  0.0432,  0.7097,  0.6702, -0.6055,  1.2293, -0.1868,  0.0260,\n",
      "         -0.0102,  0.0109, -0.2170,  0.0145,  0.6635, -0.3193,  0.0735,  0.2569,\n",
      "          0.5607, -0.7819, -0.3913, -0.3245, -0.0926,  0.3456, -0.4596, -0.1138,\n",
      "         -0.3098,  0.1310,  0.6194,  0.3829,  0.1633, -0.7929,  0.0413, -0.5963,\n",
      "         -0.0593,  0.4961, -0.1805, -0.1960,  0.1937,  0.5589, -0.0450, -0.4578,\n",
      "         -0.0496,  0.2680,  0.3041,  0.3481,  0.7526, -0.2360,  1.0559, -0.1850,\n",
      "          0.3731,  0.3414,  0.6810,  0.3672, -0.1536,  0.3572, -0.3159, -0.0767,\n",
      "          0.2654,  0.4904,  1.0650, -0.0138,  0.0997,  0.3485, -0.0205,  0.1106,\n",
      "         -0.9701, -0.5037, -0.3694, -0.2281,  0.4807,  0.1990, -0.8472, -0.3477],\n",
      "        [-0.3091,  0.0506, -0.0954,  0.0251, -0.3297,  0.1710, -0.1244,  0.1734,\n",
      "         -0.1758,  0.5475,  0.1466,  0.6807, -0.2415,  0.2185, -0.2366, -0.2712,\n",
      "         -0.1411,  0.2193,  0.0369, -0.1148,  0.0294,  0.1625, -0.1110, -0.1002,\n",
      "         -0.2579, -0.0109,  0.5007, -0.1775, -0.0234, -0.0608,  0.0335, -0.3155,\n",
      "         -0.4465,  0.3853, -0.1346, -0.0550, -0.1593,  0.0603,  0.5869,  0.0761,\n",
      "          0.1186,  0.1772,  0.3252,  0.2695,  0.0244,  0.2077, -0.0981, -0.1459,\n",
      "         -0.0778, -0.1933, -0.1442,  0.2171, -0.1795,  0.2320, -0.1269, -0.2313,\n",
      "          0.5085,  0.1859,  0.0229,  0.2707, -0.4166,  0.1216, -0.3443,  0.1240,\n",
      "          0.1542,  0.1309,  0.0316,  0.5423,  0.0660,  0.1043,  0.3171,  0.1290,\n",
      "         -0.0119,  0.0252, -0.1624,  0.0140,  0.0262,  0.3529, -0.1694, -0.0204,\n",
      "         -0.3389,  0.1596,  0.1271,  0.4593,  0.2023,  0.3462, -0.1103, -0.7464,\n",
      "         -0.2699,  0.2125, -0.4091,  0.1026,  0.1461,  0.3324,  0.0343, -0.2688,\n",
      "          0.3355,  0.8044, -0.1759,  0.1409,  0.3448,  0.0315,  0.6102,  0.2485,\n",
      "          0.4064, -0.0493,  0.3407,  0.1685, -0.1795,  0.3032, -0.1681, -0.3022,\n",
      "         -0.1240,  0.1922,  0.0158, -0.1741,  0.1769,  0.1568,  0.1129,  0.0544,\n",
      "         -0.1166, -0.2476, -0.4696, -0.0744,  0.2666,  0.2925, -0.6099,  0.2123],\n",
      "        [-0.1620,  0.3798, -0.1484,  0.4675,  0.1009,  0.0748,  0.2282, -0.1675,\n",
      "          0.1926, -0.2052, -0.0609,  0.0612,  0.4108,  0.0250, -0.1624,  0.0045,\n",
      "          0.1800,  0.1301,  0.2973, -0.5191, -0.3820,  0.3823,  0.0124, -0.0535,\n",
      "          0.0062,  0.3207,  0.3789,  0.2523,  0.2968,  0.2787, -0.4580, -0.4886,\n",
      "         -0.0374,  0.2962,  0.1529,  0.1445, -0.4780,  0.0537,  0.0254,  0.2736,\n",
      "          0.3044, -0.1274,  0.1595,  0.5293,  0.0776,  0.4560, -0.1662,  0.1743,\n",
      "          0.0041,  0.3703,  0.1614,  0.5733, -0.2122,  0.2630, -0.4036, -0.0637,\n",
      "          0.1066,  0.4765,  0.1822,  0.0710, -0.2662,  0.2416, -0.1351, -0.1644,\n",
      "         -0.1050,  0.2339, -0.1989,  0.3326, -0.3264,  0.3424,  0.1723,  0.1943,\n",
      "          0.3945, -0.0273, -0.1194, -0.3104, -0.0409,  0.4258, -0.0952,  0.3726,\n",
      "         -0.3764,  0.3662,  0.6163, -0.2671, -0.0459,  0.2682,  0.0816, -0.0934,\n",
      "          0.3359,  0.1030, -0.1760, -0.1492,  0.0891, -0.5582,  0.7109, -0.1307,\n",
      "          0.3084,  0.3604,  0.3509,  0.1644,  0.3692, -0.0668,  0.5753,  0.0531,\n",
      "          0.6702, -0.0603,  0.1062,  0.6305, -0.0292,  0.4055, -0.1163,  0.0144,\n",
      "          0.3279,  0.7888,  0.3731, -0.0811,  0.1382,  0.7139, -0.4235,  0.0045,\n",
      "         -0.1160,  0.0847, -0.5226,  0.1771,  0.0693,  0.0727, -0.2777,  0.1007]],\n",
      "       grad_fn=<SelectBackward0>)...\n",
      "=== End MultiHeadAttention Forward Pass ===\n",
      "\n",
      "Embbed_dim:  6\n",
      "\n",
      "=== FeedForward Initialization ===\n",
      "    Input and output dimensions =  6\n",
      "    Hidden dimension =  24\n",
      "=== End FeedForward Initialization ===\n",
      "\n",
      "Sample data:  tensor([[[0.4234, 0.6038, 0.1525, 0.3970, 0.8703, 0.7563],\n",
      "         [0.1836, 0.0991, 0.1583, 0.0066, 0.1142, 0.3764],\n",
      "         [0.8374, 0.5837, 0.1197, 0.0989, 0.7487, 0.1281]],\n",
      "\n",
      "        [[0.4384, 0.7399, 0.2686, 0.4455, 0.4565, 0.3817],\n",
      "         [0.2465, 0.0543, 0.0958, 0.2323, 0.9829, 0.2585],\n",
      "         [0.1642, 0.6212, 0.6378, 0.7740, 0.8801, 0.7784]]])\n",
      "\n",
      "Output shape  torch.Size([2, 3, 6])\n",
      "Output data  tensor([[[-0.2428,  0.2256,  0.1109, -0.0539,  0.3551,  0.1985],\n",
      "         [-0.1200,  0.1231,  0.0985, -0.0327,  0.2840,  0.1089],\n",
      "         [-0.2068,  0.2289,  0.0662, -0.0584,  0.3875,  0.1665]],\n",
      "\n",
      "        [[-0.2002,  0.2058,  0.1277, -0.0006,  0.3472,  0.2213],\n",
      "         [-0.1778,  0.2566,  0.1017, -0.0911,  0.3864,  0.1499],\n",
      "         [-0.2514,  0.2692,  0.1715, -0.0407,  0.3557,  0.2312]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "%run \"02. MultiHeadAttention.ipynb\"\n",
    "%run \"03. Normalization.ipynb\"\n",
    "%run \"04. FeedForward.ipynb\"\n",
    "\n",
    "MultiHeadAttention = MultiHeadAttention\n",
    "LayerNorm = LayerNorm\n",
    "FeedForward = FeedForward\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a3953f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg, verbose=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if verbose: print(f\"\\n=== Transformer Initialization ===\")\n",
    "        \n",
    "        self.embbed_dim = cfg[\"emb_dim\"]\n",
    "        self.context_length = cfg[\"context_length\"]\n",
    "        self.num_heads = cfg[\"n_heads\"]\n",
    "        self.dropout_rate = cfg[\"drop_rate\"]\n",
    "        self.qkv_bias = cfg[\"qkv_bias\"]\n",
    "\n",
    "        self.att = MultiHeadAttention(\n",
    "            input_dim = self.embbed_dim,\n",
    "            output_dim = self.embbed_dim,\n",
    "            context_length = self.context_length,\n",
    "            dropout = self.dropout_rate,\n",
    "            num_heads = self.num_heads,\n",
    "            qkv_bias = self.qkv_bias,\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        self.ffn = FeedForward(self.embbed_dim, verbose=verbose)\n",
    "        self.norm1 = LayerNorm(self.embbed_dim, verbose=verbose)\n",
    "        self.norm2 = LayerNorm(self.embbed_dim, verbose=verbose)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        print(\"Dropout rate: \", self.dropout_rate)\n",
    "\n",
    "        if verbose: print(f\"\\n=== End Transformer Initialization ===\")\n",
    "        \n",
    "\n",
    "    def forward(self, x, verbose = False):\n",
    "\n",
    "        # local variables for input shape\n",
    "        batch_size, context_length, input_dim = x.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n=== TransformerBlock Forward Pass ===\")\n",
    "            print(f\"Input shape: {x.shape} (batch_size={batch_size}, context_length={context_length}, input_dim={input_dim})\")\n",
    "            print(f\"Config: num_heads={self.num_heads}, embbed_dim={self.embbed_dim}\")\n",
    "            print(f\"\\nInput tensor (=shortcut) (batch 0 with shape {x[0].shape}):\")\n",
    "            print(f\"States for first batch ...\\n {x[0]}\")\n",
    "            \n",
    "        shortcut = x\n",
    "        \n",
    "        x = self.norm1(x)\n",
    "        if verbose: print(f\"\\n1. Normalization 1:\\n {x[0]}\")\n",
    " \n",
    "        x = self.att(x, verbose = verbose)\n",
    "        if verbose: print(f\"\\n2. Attention:\\n {x[0]}\")\n",
    " \n",
    "        x = self.dropout(x)\n",
    "        if verbose: print(f\"\\n3. Dropout:\\n {x[0]}\")\n",
    "        \n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        if verbose: print(f\"\\n4. Output + Shortcut (= new Shortcut):\\n {x[0]}\")\n",
    " \n",
    "        x = self.norm2(x)\n",
    "        if verbose: print(f\"\\n5. Normalization 2 (no verbose):\\n {x[0]}\")\n",
    "        \n",
    "        x = self.ffn(x, verbose = verbose)\n",
    "        if verbose: print(f\"\\n6. FeedForward:\\n {x[0]}\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        if verbose: print(f\"\\n7. Dropout:\\n {x[0]}\")\n",
    "        \n",
    "        x = x + shortcut\n",
    "        if verbose: \n",
    "            print(f\"\\n8. Output + new Shortcut:\\n {x[0]}\")\n",
    "            print(f\"\\n===END TransformerBlock Forward Pass ===\\n\")\n",
    "        \n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377056e1",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46ade3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Embedder Initialization ===\n",
      "    vocab_size =  50252\n",
      "    context_length =  4\n",
      "    embedding_dim =  768\n",
      "    Generating token_embeddings (50252 x 768)\n",
      "    Generating pos_embeddings (4 x 768)\n",
      "=== End Initialization ===\n",
      "\n",
      "Displaying first row of batch\n",
      "\n",
      "First batch elements Input x:\n",
      " tensor([15424,   373,   257,  5909])  archive was a vast\n",
      "\n",
      "First batch elements Target y:\n",
      " tensor([  373,   257,  5909, 16099])  was a vast repository\n",
      "\n",
      "=== Embedder Forward Pass ===\n",
      "\n",
      "embeddings[0] for x (4 x 768):\n",
      " tensor([[-0.9710, -0.7524, -0.8731,  ...,  0.7471, -0.9052, -0.2762],\n",
      "        [-1.9231, -0.6952, -1.9170,  ..., -1.5696, -0.5434,  0.5664],\n",
      "        [-0.4960, -1.1091, -0.4747,  ...,  0.8321,  0.0589,  1.5222],\n",
      "        [-0.7470, -0.4200, -0.0747,  ...,  1.1139,  0.2141, -0.1558]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "pos_embeddings[0] (4 x 768):\n",
      " tensor([[ 0.6610, -1.4272,  2.4605,  ...,  1.2418, -1.1110,  1.0747],\n",
      "        [-1.3963, -0.0800,  1.0716,  ..., -0.6346,  0.0893,  0.6827],\n",
      "        [-0.2487, -0.6259, -0.8370,  ...,  0.5769, -0.0376,  0.4348],\n",
      "        [ 0.9228,  0.5802, -0.2968,  ...,  1.3034, -0.4382,  0.5517]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "input_embeddings[0] = embeddings[0] + pos_embeddings[0]:\n",
      " tensor([[-0.3100, -2.1796,  1.5873,  ...,  1.9889, -2.0162,  0.7986],\n",
      "        [-3.3194, -0.7751, -0.8453,  ..., -2.2042, -0.4541,  1.2492],\n",
      "        [-0.7448, -1.7351, -1.3117,  ...,  1.4090,  0.0213,  1.9570],\n",
      "        [ 0.1758,  0.1602, -0.3716,  ...,  2.4173, -0.2241,  0.3959]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Shape for input_embeddings: batch, context, embedding_dim  torch.Size([8, 4, 768])\n",
      "=== End Forward Pass ===\n",
      "\n",
      "\n",
      "=== Transformer Initialization ===\n",
      "\n",
      "=== MultiHeadAttention Initialization ===\n",
      "    input_dim = 768\n",
      "    output_dim = 768\n",
      "    num_heads = 12\n",
      "    head_dim = 64\n",
      "    Generating nn.Linear(768, 768) weights for query, key and value\n",
      "    Generating causal diagonal mask torch.triu(torch.ones(1024, 1024), diagonal=1) for causal masking of attn_scores\n",
      "    Generating dropout nn.Dropout(0.1) for random dropout of attn_weights\n",
      "    Generating optional nn.Linear(768, 768) weights for final context_vector projection\n",
      "=== End MultiHeadAttention Initialization ===\n",
      "\n",
      "\n",
      "=== FeedForward Initialization ===\n",
      "    Input and output dimensions =  768\n",
      "    Hidden dimension =  3072\n",
      "=== End FeedForward Initialization ===\n",
      "\n",
      "\n",
      "=== LayerNorm Initialization ===\n",
      "    embed_dim = 768\n",
      "    Generating self.shift = nn.Parameter(torch.zeros(768))\n",
      "    Generating self.scale = nn.Parameter(torch.ones(768))\n",
      "=== End LayerNorm Initialization ===\n",
      "\n",
      "\n",
      "=== LayerNorm Initialization ===\n",
      "    embed_dim = 768\n",
      "    Generating self.shift = nn.Parameter(torch.zeros(768))\n",
      "    Generating self.scale = nn.Parameter(torch.ones(768))\n",
      "=== End LayerNorm Initialization ===\n",
      "\n",
      "Dropout rate:  0.1\n",
      "\n",
      "=== End Transformer Initialization ===\n",
      "\n",
      "=== TransformerBlock Forward Pass ===\n",
      "Input shape: torch.Size([8, 4, 768]) (batch_size=8, context_length=4, input_dim=768)\n",
      "Config: num_heads=12, embbed_dim=768\n",
      "\n",
      "Input tensor (=shortcut) (batch 0 with shape torch.Size([4, 768])):\n",
      "States for first batch ...\n",
      " tensor([[-0.3100, -2.1796,  1.5873,  ...,  1.9889, -2.0162,  0.7986],\n",
      "        [-3.3194, -0.7751, -0.8453,  ..., -2.2042, -0.4541,  1.2492],\n",
      "        [-0.7448, -1.7351, -1.3117,  ...,  1.4090,  0.0213,  1.9570],\n",
      "        [ 0.1758,  0.1602, -0.3716,  ...,  2.4173, -0.2241,  0.3959]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "1. Normalization 1:\n",
      " tensor([[-0.1554, -1.4885,  1.1975,  ...,  1.4838, -1.3720,  0.6351],\n",
      "        [-2.2864, -0.5368, -0.5850,  ..., -1.5195, -0.3160,  0.8553],\n",
      "        [-0.5828, -1.3211, -1.0055,  ...,  1.0229, -0.0117,  1.4315],\n",
      "        [ 0.1354,  0.1240, -0.2650,  ...,  1.7749, -0.1572,  0.2964]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "=== MultiHeadAttention Forward Pass ===\n",
      "Input shape: torch.Size([8, 4, 768]) (batch_size=8, context_length=4, input_dim=768)\n",
      "Config: num_heads=12, head_dim=64, output_dim=768\n",
      "\n",
      "Input tensor (batch 0 with shape torch.Size([4, 768])):\n",
      " tensor([[-0.1554, -1.4885,  1.1975,  ...,  1.4838, -1.3720,  0.6351],\n",
      "        [-2.2864, -0.5368, -0.5850,  ..., -1.5195, -0.3160,  0.8553],\n",
      "        [-0.5828, -1.3211, -1.0055,  ...,  1.0229, -0.0117,  1.4315],\n",
      "        [ 0.1354,  0.1240, -0.2650,  ...,  1.7749, -0.1572,  0.2964]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "1. QKV Projection:\n",
      "   QKV shapes: torch.Size([8, 4, 768])\n",
      "\n",
      "2. Split into heads:\n",
      "(batch_size, context_length, output_dim) -> (batch_size, context_length, head_num, head_dim)\n",
      "   QKV shapes after view: torch.Size([8, 4, 12, 64])\n",
      "\n",
      "3. Transpose for attention computation:\n",
      "(batch_size, context_length, num_heads, head_dim) -> (batch_size, num_head, context_length, head_dim)\n",
      "   QKV shapes after transpose: torch.Size([8, 12, 4, 64])\n",
      "\n",
      "4. Attention scores computation:\n",
      "   attn_scores shape: torch.Size([8, 12, 4, 4])\n",
      "   Scale factor (1/sqrt(head_dim)): 0.1250\n",
      "   Raw attention scores for head 0, batch 0:\n",
      "tensor([[ 5.9173,  2.2190, -2.5383, -1.0682],\n",
      "        [ 1.6525,  2.4131, -0.0236,  4.4639],\n",
      "        [-0.8495, -0.4249,  3.1302,  1.2707],\n",
      "        [ 6.7474, -0.3419,  1.6015, -1.8065]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "5. Causal masking:\n",
      "   Causal mask:\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "   Then masked_fill True -> -torch.inf\n",
      "\n",
      "   Masked attention scores for head 0, batch 0:\n",
      "tensor([[ 5.9173,    -inf,    -inf,    -inf],\n",
      "        [ 1.6525,  2.4131,    -inf,    -inf],\n",
      "        [-0.8495, -0.4249,  3.1302,    -inf],\n",
      "        [ 6.7474, -0.3419,  1.6015, -1.8065]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "6. Softmax attention weights:\n",
      "   attn_weights shape: torch.Size([8, 12, 4, 4])\n",
      "   Attention weights for head 0, batch 0:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4763, 0.5237, 0.0000, 0.0000],\n",
      "        [0.2703, 0.2851, 0.4446, 0.0000],\n",
      "        [0.4384, 0.1807, 0.2304, 0.1505]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "   Sum of weights (should be ~1.0): tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
      "\n",
      "7. After dropout:\n",
      "   Attention weights after dropout for head 0, batch 0:\n",
      "tensor([[1.1111, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5292, 0.5819, 0.0000, 0.0000],\n",
      "        [0.3004, 0.0000, 0.4940, 0.0000],\n",
      "        [0.4871, 0.2008, 0.2560, 0.1672]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "8. Compute context vectors:\n",
      "   context_vec shape after attention: torch.Size([8, 4, 12, 64])\n",
      "   First context vector (batch 0, token 0, head 0): tensor([-0.7285,  0.6055,  0.5407,  0.3296, -0.0759,  0.5275, -0.2794, -0.4378,\n",
      "         0.7365, -0.9950,  0.8479, -0.7492,  0.5299, -0.2358,  0.0458,  0.0544,\n",
      "        -0.0534,  0.8055, -0.5412,  0.8077, -0.9111, -0.3523,  0.5438, -0.6156,\n",
      "        -0.2842, -0.5368, -0.6582,  0.3061, -0.2230, -0.1409,  0.3166, -0.8487,\n",
      "         1.4261, -1.0615, -0.5018,  0.2278, -0.0843,  0.0190, -0.3441, -0.2519,\n",
      "        -0.9802,  0.7600, -0.1101, -0.8807,  0.6368,  0.2366,  0.3247, -0.1360,\n",
      "        -0.1510, -1.0990, -0.5423,  0.2871,  0.0871, -0.4979, -0.7211, -0.0864,\n",
      "        -1.1947, -0.4199, -0.2923,  0.0581, -0.1662, -0.3041,  0.4352,  0.2047],\n",
      "       grad_fn=<SelectBackward0>)...\n",
      "\n",
      "9. Concatenate heads:\n",
      "   context_vec shape after view: torch.Size([8, 4, 768])\n",
      "   First concatenated context vector (batch 0): tensor([[-0.7285,  0.6055,  0.5407,  ...,  0.7011,  0.5506,  1.2655],\n",
      "        [-0.3668,  0.4573, -0.2927,  ...,  0.4582,  0.3691,  0.8678],\n",
      "        [ 0.1416, -0.1479,  0.2244,  ...,  0.2397, -0.0356,  0.6006],\n",
      "        [-0.0542,  0.1312,  0.0183,  ...,  0.4615,  0.1795,  0.6116]],\n",
      "       grad_fn=<SelectBackward0>)...\n",
      "\n",
      "10. Final output projection:\n",
      "   Final context_vec shape: torch.Size([8, 4, 768])\n",
      "   Final context vector (batch 0): tensor([[ 0.2814,  0.3157, -0.2198,  ..., -0.2446,  0.0405, -0.0445],\n",
      "        [ 0.1559,  0.0256, -0.2838,  ..., -0.5078, -0.0906,  0.2196],\n",
      "        [-0.1220, -0.1169, -0.1949,  ..., -0.0851,  0.0557,  0.3200],\n",
      "        [-0.1787,  0.1156, -0.3130,  ..., -0.3219,  0.0969,  0.1879]],\n",
      "       grad_fn=<SelectBackward0>)...\n",
      "=== End MultiHeadAttention Forward Pass ===\n",
      "\n",
      "\n",
      "2. Attention:\n",
      " tensor([[ 0.2814,  0.3157, -0.2198,  ..., -0.2446,  0.0405, -0.0445],\n",
      "        [ 0.1559,  0.0256, -0.2838,  ..., -0.5078, -0.0906,  0.2196],\n",
      "        [-0.1220, -0.1169, -0.1949,  ..., -0.0851,  0.0557,  0.3200],\n",
      "        [-0.1787,  0.1156, -0.3130,  ..., -0.3219,  0.0969,  0.1879]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "3. Dropout:\n",
      " tensor([[ 0.0000,  0.3508, -0.2443,  ..., -0.2718,  0.0450, -0.0495],\n",
      "        [ 0.1732,  0.0285, -0.3153,  ..., -0.5643, -0.1007,  0.2440],\n",
      "        [-0.1355, -0.1298, -0.2165,  ..., -0.0945,  0.0618,  0.3556],\n",
      "        [-0.1985,  0.1284, -0.3478,  ..., -0.3577,  0.1077,  0.2088]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "4. Output + Shortcut (= new Shortcut):\n",
      " tensor([[-0.3100, -1.8288,  1.3431,  ...,  1.7171, -1.9712,  0.7491],\n",
      "        [-3.1463, -0.7467, -1.1607,  ..., -2.7685, -0.5548,  1.4932],\n",
      "        [-0.8803, -1.8649, -1.5282,  ...,  1.3145,  0.0831,  2.3126],\n",
      "        [-0.0227,  0.2887, -0.7194,  ...,  2.0596, -0.1165,  0.6047]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "5. Normalization 2 (no verbose):\n",
      " tensor([[-0.1408, -1.1830,  0.9935,  ...,  1.2501, -1.2807,  0.5859],\n",
      "        [-2.1515, -0.5144, -0.7968,  ..., -1.8938, -0.3835,  1.0137],\n",
      "        [-0.6743, -1.3957, -1.1490,  ...,  0.9336,  0.0315,  1.6648],\n",
      "        [-0.0143,  0.2117, -0.5201,  ...,  1.4974, -0.0824,  0.4412]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "6. FeedForward:\n",
      " tensor([[-0.2427, -0.0712,  0.0588,  ..., -0.0942, -0.0479,  0.3223],\n",
      "        [-0.3213,  0.1559,  0.1941,  ..., -0.1694,  0.0281, -0.1347],\n",
      "        [ 0.0557,  0.1569, -0.1024,  ...,  0.4714, -0.0099, -0.2526],\n",
      "        [-0.2444,  0.0506, -0.3424,  ..., -0.0046,  0.0467,  0.3079]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "7. Dropout:\n",
      " tensor([[-0.2696, -0.0791,  0.0653,  ..., -0.1046, -0.0532,  0.3581],\n",
      "        [-0.3569,  0.1732,  0.2157,  ..., -0.1882,  0.0312, -0.1497],\n",
      "        [ 0.0619,  0.1743, -0.1138,  ...,  0.5238, -0.0110, -0.2807],\n",
      "        [-0.2716,  0.0562, -0.3805,  ..., -0.0051,  0.0518,  0.3421]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "8. Output + new Shortcut:\n",
      " tensor([[-0.5796, -1.9079,  1.4084,  ...,  1.6124, -2.0244,  1.1072],\n",
      "        [-3.5032, -0.5735, -0.9450,  ..., -2.9567, -0.5236,  1.3435],\n",
      "        [-0.8184, -1.6906, -1.6420,  ...,  1.8383,  0.0722,  2.0319],\n",
      "        [-0.2942,  0.3449, -1.0998,  ...,  2.0545, -0.0646,  0.9469]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "===END TransformerBlock Forward Pass ===\n",
      "\n",
      "Output shape:  torch.Size([8, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "def use_transformer_block(verbose = False):\n",
    "\n",
    "    %run \"01. DataPreparation.ipynb\"\n",
    "    input = get_test_input_embedding(verbose=verbose)\n",
    "\n",
    "    block = TransformerBlock(cfg = GPT_CONFIG_124M, verbose=verbose)\n",
    "    y = block(input, verbose=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Output shape: \", y.shape)\n",
    "\n",
    "_test_run = use_transformer_block(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35223b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
