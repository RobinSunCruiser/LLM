{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f964f10f",
   "metadata": {},
   "source": [
    "# Playground for FeedForward Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb2765",
   "metadata": {},
   "source": [
    "## GELU Activation\n",
    "* Use Gaussian Error Linear Unit (GeLU) instead of ReLU\n",
    "    * More Smooth than ReLU f√ºr better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225ec960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_printoptions(threshold=10, edgeitems=3)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GELU(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x,3))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18676e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_GELU_and_RELU():\n",
    "\n",
    "    x = torch.linspace(-3, 3, 100) # sample data\n",
    "\n",
    "    gelu = GELU()\n",
    "    relu = nn.ReLU()\n",
    "\n",
    "    y_gelu = gelu(x)\n",
    "    y_relu = relu(x)\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "        plt.subplot(1, 2, i)\n",
    "        plt.plot(x, y)\n",
    "        plt.title(f\"{label} activation function\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(f\"{label}(x)\")\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# _test_plot = plot_GELU_and_RELU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb54bf",
   "metadata": {},
   "source": [
    "## FeedForward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fa754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, verbose=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_dim = 4 * emb_dim # some common convention\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hidden_dim),\n",
    "            GELU(),\n",
    "            nn.Linear(hidden_dim, emb_dim),\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n=== FeedForward Initialization ===\")\n",
    "            print(f\"    Input and output dimensions = \", emb_dim)\n",
    "            print(f\"    Hidden dimension = \",hidden_dim)        \n",
    "            print(f\"=== End FeedForward Initialization ===\\n\")\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fa054",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75995a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embbed_dim:  6\n",
      "\n",
      "=== FeedForward Initialization ===\n",
      "    Input and output dimensions =  6\n",
      "    Hidden dimension =  24\n",
      "=== End FeedForward Initialization ===\n",
      "\n",
      "Sample data:  tensor([[[0.4234, 0.6038, 0.1525, 0.3970, 0.8703, 0.7563],\n",
      "         [0.1836, 0.0991, 0.1583, 0.0066, 0.1142, 0.3764],\n",
      "         [0.8374, 0.5837, 0.1197, 0.0989, 0.7487, 0.1281]],\n",
      "\n",
      "        [[0.4384, 0.7399, 0.2686, 0.4455, 0.4565, 0.3817],\n",
      "         [0.2465, 0.0543, 0.0958, 0.2323, 0.9829, 0.2585],\n",
      "         [0.1642, 0.6212, 0.6378, 0.7740, 0.8801, 0.7784]]])\n",
      "\n",
      "Output shape  torch.Size([2, 3, 6])\n",
      "Output data  tensor([[[-0.2428,  0.2256,  0.1109, -0.0539,  0.3551,  0.1985],\n",
      "         [-0.1200,  0.1231,  0.0985, -0.0327,  0.2840,  0.1089],\n",
      "         [-0.2068,  0.2289,  0.0662, -0.0584,  0.3875,  0.1665]],\n",
      "\n",
      "        [[-0.2002,  0.2058,  0.1277, -0.0006,  0.3472,  0.2213],\n",
      "         [-0.1778,  0.2566,  0.1017, -0.0911,  0.3864,  0.1499],\n",
      "         [-0.2514,  0.2692,  0.1715, -0.0407,  0.3557,  0.2312]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def test_feedForward(verbose = False):\n",
    "\n",
    "    embbed_dim = 6\n",
    "    print(f'Embbed_dim: ', embbed_dim)\n",
    "\n",
    "    ffn = FeedForward(embbed_dim, verbose=verbose)\n",
    "\n",
    "    x = torch.rand(2, 3, embbed_dim) # 2 batches, 3 context_length, embed_dim\n",
    "    print(\"Sample data: \", x)\n",
    "\n",
    "    out = ffn(x, verbose=verbose)\n",
    "\n",
    "    print(\"\\nOutput shape \", out.shape)\n",
    "    print(\"Output data \", out )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": _test_run = test_feedForward(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66b4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
